{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51bd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "RETRIEVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be8a7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://whoicf2.whoi.edu/science/B/whalesounds/metaData.cfm?RN='\n",
    "\n",
    "ds_path = 'dataset'\n",
    "full_ds_path = 'full_dataset'\n",
    "if not os.path.exists(full_ds_path):\n",
    "    os.makedirs(full_ds_path)\n",
    "if not os.path.exists(ds_path):\n",
    "    os.makedirs(ds_path)\n",
    "    \n",
    "# Campi dei metadati da estrarre\n",
    "col = ['filename', 'CU:', 'SR:', 'CS:']\n",
    "metadata_df = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb06929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per l'estrazione dei metadati\n",
    "def retrieve_metadata(folder_path, base_url):\n",
    "    ret_list = []\n",
    "    for f in os.listdir(folder_path):\n",
    "        fn = f.split('.')[0]\n",
    "        curr_dict = {}\n",
    "        curr_url = base_url + fn\n",
    "        curr_dict['filename'] = fn\n",
    "        curr_dict['species'] = f\n",
    "\n",
    "        # Richiesta html e parsing della tabella\n",
    "        html = requests.get(curr_url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        rows = soup.find_all('tr')\n",
    "\n",
    "        # Estrazione dei dati dalla tabella\n",
    "        campi_desiderati = col[1:]\n",
    "        for row in rows:\n",
    "            celle = row.find_all('td')\n",
    "            if len(celle) == 2:\n",
    "                chiave = celle[0].get_text(strip=True)\n",
    "                valore = celle[1].get_text(strip=True)\n",
    "                if chiave in campi_desiderati:\n",
    "                    curr_dict[chiave] = valore\n",
    "        ret_list.append(curr_dict)\n",
    "\n",
    "    return ret_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei metadati di tutte le specie in un unico file csv\n",
    "if RETRIEVE:\n",
    "    for folder in os.listdir('dataset'):\n",
    "        folder_dict = retrieve_metadata(Path(ds_path, folder), base_url)\n",
    "        metadata_df = pd.concat([metadata_df, pd.DataFrame.from_records(folder_dict)], ignore_index=True)\n",
    "    metadata_df.to_csv('metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_df = pd.read_csv(Path('metadata', 'metadata.csv'))\n",
    "md_df['filename'] = md_df['filename'].apply(lambda x: x[:5])\n",
    "md_df = md_df.drop_duplicates(subset=['filename'])\n",
    "print(md_df.shape)\n",
    "\n",
    "def check_full_audio(row, ret_list):\n",
    "    url = f\"https://whoicf2.whoi.edu/science/B/whalesounds/WhaleSounds/MasterFiles/{row['filename']}.zip\"\n",
    "    curr_list = []\n",
    "    request = requests.get(url, stream=True, allow_redirects=True, timeout=10)\n",
    "    if request.status_code == 200:\n",
    "        curr_list = [row['species'], row['filename'], True]\n",
    "        print(f'{row['species']} - {row['filename']}: True')\n",
    "    else:\n",
    "        curr_list = [row['species'], row['filename'], False]\n",
    "        print(f'{row['species']} - {row['filename']}: False')\n",
    "    ret_list.append(curr_list)\n",
    "    time.sleep(2)\n",
    "\n",
    "df_list = []\n",
    "md_df.apply(check_full_audio, args=(df_list,), axis=1)\n",
    "df = pd.DataFrame(df_list, columns=['species', 'filename', 'full_audio'])\n",
    "df.to_csv(Path('metadata','full_audio.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f1d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path('metadata', 'full_audio.csv'))\n",
    "download_df = df[df['full_audio'] == True]\n",
    "popular_species = pd.read_csv(Path('metadata', 'species_count.csv'))\n",
    "popular_species = popular_species[popular_species['file_count'] > 999]\n",
    "restricted_link = download_df[download_df['species'].isin(popular_species['species'])]\n",
    "\n",
    "def link_generator(row):\n",
    "    link_list = []\n",
    "    url = f\"https://whoicf2.whoi.edu/science/B/whalesounds/WhaleSounds/MasterFiles/{row['filename']}.zip\"\n",
    "    link_list.append(url)\n",
    "    return link_list\n",
    "link_df = restricted_link.apply(link_generator, axis=1)\n",
    "# scrivere la lista di link in un file di testo in modo da avere un link per riga\n",
    "with open('link_list.txt', 'w') as f:\n",
    "    for link in link_df:\n",
    "        for l in link:\n",
    "            f.write(f\"{l}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mmd_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
